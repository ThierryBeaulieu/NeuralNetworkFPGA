{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 : Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('x.npy') # 5000 images\n",
    "y = np.load('y.npy')\n",
    "\n",
    "theta_0 = np.load('theta_0.npy')\n",
    "theta_1 = np.load('theta_1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Function that Converts Floating Point Precision to Fixed Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_0 [-1.463369, 1.00899]\n",
    "# 4 bits [1 signed, 1 integer, 2 fractional]\n",
    "def convert_float_to_fix_point(floating_value: float, signed: int, integer: int, fractional: int):\n",
    "    # With fixed precision, only certain values are possible\n",
    "    # \n",
    "    # For instance, the possible values for 1 bit signed, 1 bit integer and 2 bits signed are :\n",
    "    # 1111, 1110, 1101, 1100, 1011, 1010, 1001, 1000, 0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111\n",
    "    # {-1.75, -1.50, -1.25, -1.0, -0.75, -0.5, -0.25, -0.0, 0.0 , 0.25, 0.50, 0.75, 1.00, 1.25, 1.50, 1.75}\n",
    "\n",
    "    # The fixed point notation only affects the uncertainty \n",
    "    # We therefore can keep \"floating point values\" by reducing there precision\n",
    "    # This avoid converting floating points to binary and then converting a binary back\n",
    "    # to the floating point notation\n",
    "    if signed > 1:\n",
    "        raise Exception(\"The signed bit can't be more than 1\")\n",
    "    if signed == 0 and floating_value < 0:\n",
    "        raise Exception(\"Can't convert the negative floating number without a bit for the sign\")\n",
    "    if (signed + integer + fractional) not in [4, 6, 8, 10, 12, 14, 16]:\n",
    "        raise Exception(\"The sum doesn't add up to a valid configuration\")\n",
    "    \n",
    "    res = 0.0\n",
    "    integer_part = abs(int(floating_value))\n",
    "    fractional_part = abs(floating_value) - integer_part\n",
    "\n",
    "    # This is the maximum value an integer can be according to precision\n",
    "    max_integer = {n: (2 ** n) - 1 for n in range(17)}\n",
    "\n",
    "    # This is the maximum value of fractional part according to precision\n",
    "    max_fractional = {n: 1 / (2 ** n) for n in range(17)} \n",
    "\n",
    "    if integer_part > max_integer[integer]:\n",
    "        integer_part = max_integer[integer]\n",
    "\n",
    "        for i in range(1, fractional + 1):\n",
    "            fractional_part = fractional_part + max_fractional[i]\n",
    "\n",
    "        res = integer_part + fractional_part\n",
    "        if signed == 1 and floating_value < 0.0:\n",
    "            res = res * -1\n",
    "        return res\n",
    "    \n",
    "    rest = fractional_part\n",
    "    fractional_part = 0\n",
    "    for i in range(1, fractional + 1):\n",
    "        if rest > max_fractional[i]:\n",
    "            rest -= max_fractional[i]\n",
    "            fractional_part += max_fractional[i]\n",
    "            \n",
    "    res = integer_part + fractional_part\n",
    "\n",
    "    if signed == 1 and floating_value < 0.0:\n",
    "        res = res * -1\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "assert(-4 == convert_float_to_fix_point(-4.0, 1, 3, 0))\n",
    "assert(-4 == convert_float_to_fix_point(-4.2, 1, 3, 0)) \n",
    "assert(-1 == convert_float_to_fix_point(-1.9999, 1, 3, 0)) \n",
    "assert(-1.75 == convert_float_to_fix_point(-1.9999, 1, 1, 2))\n",
    "assert(3.75 == convert_float_to_fix_point(3.98, 0, 2, 2))\n",
    "assert(-1.75 == convert_float_to_fix_point(-1.98, 1, 1, 2))\n",
    "assert(0.9375 == convert_float_to_fix_point(4.0, 0, 0, 4))\n",
    "assert(63.25 == convert_float_to_fix_point(63.4, 0, 6, 2))\n",
    "assert(0.9375 == convert_float_to_fix_point(1.0, 0, 0, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Convert Pixel Precision Into Fixed Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image [0.0, 1.0[\n",
    "# 4 bits [0 signed, 0 integer, 4 fractional]\n",
    "\n",
    "imgIndex = 0\n",
    "image = x[imgIndex]\n",
    "xp = np.hstack((1, image))\n",
    "\n",
    "image_fp = np.zeros_like(xp)\n",
    "\n",
    "for i in range(xp.shape[0]):\n",
    "    image_fp[i] = convert_float_to_fix_point(xp[i], 0, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Convert Weight Precision Into Fixed Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight [-1.463356, 1.00899]\n",
    "# 4 bits [1 signed, 1 integer, 2 fractional]\n",
    "theta_0_fp = np.zeros_like(theta_0)\n",
    "for i in range(theta_0.shape[0]): # 25\n",
    "    for j in range(theta_0.shape[1]): # 401\n",
    "        theta_0_fp[i][j] = convert_float_to_fix_point(theta_0[i][j], 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Make The First Hidden Layer Multiplication X*W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenLayer_fp = np.zeros(theta_0.shape[0])\n",
    "\n",
    "for i in range(0, len(theta_0_fp)): # [0, 24]\n",
    "    row = theta_0_fp[i]\n",
    "    product = 0\n",
    "    for j in range(0, len(row)): # [0, 400]\n",
    "        weight_fp = row[j]\n",
    "        pixel_fp = image_fp[j]\n",
    "        product = product + weight_fp * pixel_fp\n",
    "    hiddenLayer_fp[i] = product\n",
    "\n",
    "# [-3.78125, 4.796875]\n",
    "# 4 bits [1 signed, 3 integer, 0 fractional] \n",
    "for i in range(0, len(hiddenLayer_fp)):\n",
    "    hiddenLayer_fp[i] = convert_float_to_fix_point(hiddenLayer_fp[i], 1, 3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Apply the Sigmoid Function For First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid1_fp = np.zeros(hiddenLayer_fp.shape[0])\n",
    "\n",
    "for i in range(0, len(hiddenLayer_fp)):\n",
    "    tmp = sigmoid(hiddenLayer_fp[i])\n",
    "    # Range of a sigmoid is always [0, 1]\n",
    "    sigmoid1_fp[i] = convert_float_to_fix_point(tmp, 0, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Convert Weight of Second Layer Precision Into Fixed Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight [-4.0308, 3.2115848]\n",
    "# 4 bits [1 signed, 3 integer, 0 fractional]\n",
    "theta_1_fp = np.zeros_like(theta_1)\n",
    "for i in range(theta_1.shape[0]): # 10\n",
    "    for j in range(theta_1.shape[1]): # 26\n",
    "        theta_1_fp[i][j] = convert_float_to_fix_point(theta_1[i][j], 1, 3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Make The Second Hidden Layer Multiplication X*W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7. Apply the Sigmoid Function For Second Hidden Layer\n",
    "\n",
    "## Step 8. Display FPGA Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle Théorique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPGA Output: [1.07100260e-04 1.77685215e-03 2.55111054e-03 1.88649313e-05\n",
      " 8.48248959e-03 4.12322127e-03 5.31080097e-03 4.28542960e-04\n",
      " 6.02356752e-03 9.95800902e-01]\n",
      "Prediction: 9 Label: 9\n"
     ]
    }
   ],
   "source": [
    "x = np.load('x.npy') # 5000 images\n",
    "y = np.load('y.npy')\n",
    "\n",
    "theta_0 = np.load('theta_0.npy')\n",
    "theta_1 = np.load('theta_1.npy')\n",
    "\n",
    "# Calculer sur le FPGA\n",
    "xp = np.hstack((1, image)) # Ajouter 1 pour le biais\n",
    "hiddenLayer1 = np.dot(xp,theta_0.T)\n",
    "\n",
    "a = sigmoid(hiddenLayer1) # Sortie de la couche 1\n",
    "ap = np.hstack((1, a)) # Ajouter 1 pour le biais\n",
    "b = sigmoid(np.dot(ap,theta_1.T)) # Sortie de la couche 2\n",
    "print(\"FPGA Output:\",b)\n",
    "\n",
    "# Calculer dans le notebook\n",
    "pred = b.argmax()\n",
    "print(\"Prediction:\", pred, \"Label:\", y[imgIndex])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
